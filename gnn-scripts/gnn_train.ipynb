{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7ef5869b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ef5869b",
        "outputId": "08a12f2a-73de-43f8-fe85-a1c072e2d5c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Running on Google Colab\n",
            "\n",
            "TensorFlow version: 2.19.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "üöÄ GPU detected! Training will be accelerated.\n"
          ]
        }
      ],
      "source": [
        "# Check if running on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"‚úÖ Running on Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"üìù Running on local Jupyter\")\n",
        "\n",
        "# Check GPU availability\n",
        "import tensorflow as tf\n",
        "print(f\"\\nTensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"üöÄ GPU detected! Training will be accelerated.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected. Training will be slower on CPU.\")\n",
        "    if IN_COLAB:\n",
        "        print(\"üí° Enable GPU: Runtime > Change runtime type > Hardware accelerator > GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ba69719b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba69719b",
        "outputId": "3d78e267-70d3-412c-bf72-c95cabe7fef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EstraNet'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 140 (delta 71), reused 117 (delta 48), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (140/140), 3.13 MiB | 9.44 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "‚úÖ Clean! Directory: /content/EstraNet\n"
          ]
        }
      ],
      "source": [
        "import os, shutil\n",
        "\n",
        "os.chdir('/content')\n",
        "if os.path.exists('EstraNet'):\n",
        "    shutil.rmtree('EstraNet')  # Remove nested mess\n",
        "\n",
        "!git clone https://github.com/loshithan/EstraNet.git\n",
        "os.chdir('EstraNet')\n",
        "print(f\"‚úÖ Clean! Directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5c4307c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c4307c1",
        "outputId": "8407910e-0822-43c1-edda-3c416329ab15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading ASCADf dataset from Google Drive...\n",
            "   This may take a few minutes (~1.5 GB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WNajWT0qFbpqPJiuePS_HeXxsCvUHI5M\n",
            "To: /content/EstraNet/data/ASCAD.h5\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46.6M/46.6M [00:00<00:00, 112MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Dataset downloaded successfully!\n",
            "\n",
            "üìä Dataset info:\n",
            "  Keys: ['Attack_traces', 'Profiling_traces']\n",
            "  Profiling traces shape: (50000, 700)\n",
            "  Attack traces shape: (10000, 700)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "# Create data directory\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# ASCADf dataset configuration\n",
        "file_id = \"1WNajWT0qFbpqPJiuePS_HeXxsCvUHI5M\"\n",
        "DATASET_PATH = \"data/ASCAD.h5\"\n",
        "\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    print(\"üì• Downloading ASCADf dataset from Google Drive...\")\n",
        "    print(\"   This may take a few minutes (~1.5 GB)\\n\")\n",
        "\n",
        "    # Download using gdown\n",
        "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", DATASET_PATH, quiet=False)\n",
        "\n",
        "    print(\"\\n‚úÖ Dataset downloaded successfully!\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already exists\")\n",
        "\n",
        "# Verify dataset\n",
        "import h5py\n",
        "with h5py.File(DATASET_PATH, 'r') as f:\n",
        "    print(f\"\\nüìä Dataset info:\")\n",
        "    print(f\"  Keys: {list(f.keys())}\")\n",
        "    if 'Profiling_traces' in f:\n",
        "        print(f\"  Profiling traces shape: {f['Profiling_traces/traces'].shape}\")\n",
        "    if 'Attack_traces' in f:\n",
        "        print(f\"  Attack traces shape: {f['Attack_traces/traces'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "027da6d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "027da6d8",
        "outputId": "5b0193a4-8f2b-4dc9-a636-3de6bbeb7f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing dependencies...\n",
            "\n",
            "\n",
            "‚úÖ All dependencies installed!\n",
            "Using TensorFlow 2.19.0 (pre-installed)\n"
          ]
        }
      ],
      "source": [
        "# Install required dependencies\n",
        "print(\"üì¶ Installing dependencies...\\n\")\n",
        "# %pip install -q absl-py==2.3.1 numpy==1.24.3 scipy==1.10.1 h5py==3.11.0\n",
        "\n",
        "# Install gdown for downloading from Google Drive\n",
        "%pip install -q gdown\n",
        "\n",
        "# Note: Using TensorFlow version pre-installed in Colab (2.16+ / 2.19+)\n",
        "# The compatibility fixes in Section 3 work with all TensorFlow 2.13+ versions\n",
        "print(\"\\n‚úÖ All dependencies installed!\")\n",
        "print(f\"Using TensorFlow {tf.__version__} (pre-installed)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8fd80811",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fd80811",
        "outputId": "9a4b9152-91f7-46d8-b00e-6708a41dd5dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî∑ Training GNN Model\n",
            "======================================================================\n",
            "Starting GNN training...\n",
            "Model: GNN (211,876 parameters - 51% less than Transformer)\n",
            "Checkpoints: /content/drive/MyDrive/EstraNet/checkpoints_gnn\n",
            "Training steps: 5,000\n",
            "\n",
            "2026-02-13 04:13:22.652503: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770956002.673303    7557 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770956002.680023    7557 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770956002.695943    7557 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770956002.695972    7557 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770956002.695975    7557 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770956002.695978    7557 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "‚úÖ File replaced with fixed version\n",
            "‚úÖ Checkpoints deleted\n",
            "\n",
            "‚ö†Ô∏è  NOW RESTART RUNTIME: Runtime ‚Üí Restart runtime\n",
            "Then run your training again\n",
            "INFO:tensorflow:\n",
            "I0213 04:13:28.836463 134220221252736 train_trans.py:429] \n",
            "INFO:tensorflow:\n",
            "I0213 04:13:28.836743 134220221252736 train_trans.py:430] \n",
            "INFO:tensorflow:use_tpu               : False\n",
            "I0213 04:13:28.836864 134220221252736 train_trans.py:431] use_tpu               : False\n",
            "INFO:tensorflow:data_path             : data/ASCAD.h5\n",
            "I0213 04:13:28.836945 134220221252736 train_trans.py:432] data_path             : data/ASCAD.h5\n",
            "INFO:tensorflow:dataset               : ASCAD\n",
            "I0213 04:13:28.837015 134220221252736 train_trans.py:433] dataset               : ASCAD\n",
            "INFO:tensorflow:checkpoint_dir        : /content/drive/MyDrive/EstraNet/checkpoints_gnn\n",
            "I0213 04:13:28.837079 134220221252736 train_trans.py:434] checkpoint_dir        : /content/drive/MyDrive/EstraNet/checkpoints_gnn\n",
            "INFO:tensorflow:checkpoint_idx        : 0\n",
            "I0213 04:13:28.837141 134220221252736 train_trans.py:435] checkpoint_idx        : 0\n",
            "INFO:tensorflow:warm_start            : False\n",
            "I0213 04:13:28.837200 134220221252736 train_trans.py:436] warm_start            : False\n",
            "INFO:tensorflow:result_path           : results/gnn\n",
            "I0213 04:13:28.837259 134220221252736 train_trans.py:437] result_path           : results/gnn\n",
            "INFO:tensorflow:do_train              : True\n",
            "I0213 04:13:28.837317 134220221252736 train_trans.py:438] do_train              : True\n",
            "INFO:tensorflow:learning_rate         : 0.00025\n",
            "I0213 04:13:28.837379 134220221252736 train_trans.py:439] learning_rate         : 0.00025\n",
            "INFO:tensorflow:clip                  : 0.25\n",
            "I0213 04:13:28.837441 134220221252736 train_trans.py:440] clip                  : 0.25\n",
            "INFO:tensorflow:min_lr_ratio          : 0.004\n",
            "I0213 04:13:28.837500 134220221252736 train_trans.py:441] min_lr_ratio          : 0.004\n",
            "INFO:tensorflow:warmup_steps          : 0\n",
            "I0213 04:13:28.837558 134220221252736 train_trans.py:442] warmup_steps          : 0\n",
            "INFO:tensorflow:input_length          : 700\n",
            "I0213 04:13:28.837615 134220221252736 train_trans.py:443] input_length          : 700\n",
            "INFO:tensorflow:data_desync           : 0\n",
            "I0213 04:13:28.837672 134220221252736 train_trans.py:444] data_desync           : 0\n",
            "INFO:tensorflow:train_batch_size      : 256\n",
            "I0213 04:13:28.837739 134220221252736 train_trans.py:445] train_batch_size      : 256\n",
            "INFO:tensorflow:eval_batch_size       : 32\n",
            "I0213 04:13:28.837799 134220221252736 train_trans.py:446] eval_batch_size       : 32\n",
            "INFO:tensorflow:train_steps           : 5000\n",
            "I0213 04:13:28.837863 134220221252736 train_trans.py:447] train_steps           : 5000\n",
            "INFO:tensorflow:iterations            : 500\n",
            "I0213 04:13:28.837923 134220221252736 train_trans.py:448] iterations            : 500\n",
            "INFO:tensorflow:save_steps            : 200\n",
            "I0213 04:13:28.837981 134220221252736 train_trans.py:449] save_steps            : 200\n",
            "INFO:tensorflow:n_layer               : 2\n",
            "I0213 04:13:28.838038 134220221252736 train_trans.py:450] n_layer               : 2\n",
            "INFO:tensorflow:d_model               : 128\n",
            "I0213 04:13:28.838096 134220221252736 train_trans.py:451] d_model               : 128\n",
            "INFO:tensorflow:d_head                : 32\n",
            "I0213 04:13:28.838154 134220221252736 train_trans.py:452] d_head                : 32\n",
            "INFO:tensorflow:n_head                : 4\n",
            "I0213 04:13:28.838213 134220221252736 train_trans.py:453] n_head                : 4\n",
            "INFO:tensorflow:d_inner               : 256\n",
            "I0213 04:13:28.838271 134220221252736 train_trans.py:454] d_inner               : 256\n",
            "INFO:tensorflow:n_head_softmax        : 8\n",
            "I0213 04:13:28.838330 134220221252736 train_trans.py:455] n_head_softmax        : 8\n",
            "INFO:tensorflow:d_head_softmax        : 16\n",
            "I0213 04:13:28.838392 134220221252736 train_trans.py:456] d_head_softmax        : 16\n",
            "INFO:tensorflow:dropout               : 0.05\n",
            "I0213 04:13:28.838453 134220221252736 train_trans.py:457] dropout               : 0.05\n",
            "INFO:tensorflow:conv_kernel_size      : 3\n",
            "I0213 04:13:28.838512 134220221252736 train_trans.py:458] conv_kernel_size      : 3\n",
            "INFO:tensorflow:n_conv_layer          : 2\n",
            "I0213 04:13:28.838571 134220221252736 train_trans.py:459] n_conv_layer          : 2\n",
            "INFO:tensorflow:pool_size             : 2\n",
            "I0213 04:13:28.838630 134220221252736 train_trans.py:460] pool_size             : 2\n",
            "INFO:tensorflow:d_kernel_map          : 128\n",
            "I0213 04:13:28.838689 134220221252736 train_trans.py:461] d_kernel_map          : 128\n",
            "INFO:tensorflow:beta_hat_2            : 150\n",
            "I0213 04:13:28.838762 134220221252736 train_trans.py:462] beta_hat_2            : 150\n",
            "INFO:tensorflow:model_normalization   : preLC\n",
            "I0213 04:13:28.838824 134220221252736 train_trans.py:463] model_normalization   : preLC\n",
            "INFO:tensorflow:head_initialization   : forward\n",
            "I0213 04:13:28.838891 134220221252736 train_trans.py:464] head_initialization   : forward\n",
            "INFO:tensorflow:softmax_attn          : True\n",
            "I0213 04:13:28.838951 134220221252736 train_trans.py:465] softmax_attn          : True\n",
            "INFO:tensorflow:max_eval_batch        : -1\n",
            "I0213 04:13:28.839011 134220221252736 train_trans.py:466] max_eval_batch        : -1\n",
            "INFO:tensorflow:output_attn           : False\n",
            "I0213 04:13:28.839071 134220221252736 train_trans.py:467] output_attn           : False\n",
            "INFO:tensorflow:\n",
            "I0213 04:13:28.839128 134220221252736 train_trans.py:468] \n",
            "INFO:tensorflow:\n",
            "I0213 04:13:28.839189 134220221252736 train_trans.py:469] \n",
            "INFO:tensorflow:Number of accelerators: 1\n",
            "I0213 04:13:56.501759 134220221252736 train_trans.py:509] Number of accelerators: 1\n",
            "INFO:tensorflow:num of train batches 195\n",
            "I0213 04:13:56.501937 134220221252736 train_trans.py:532] num of train batches 195\n",
            "INFO:tensorflow:num of test batches 312\n",
            "I0213 04:13:56.502000 134220221252736 train_trans.py:533] num of test batches 312\n",
            "2026-02-13 04:13:56.771843: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770956036.774109    7557 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79188 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:05.0, compute capability: 8.0\n",
            "I0213 04:13:56.991710 134220221252736 functional_saver.py:440] Sharding callback duration: 10 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-1\n",
            "I0213 04:13:57.007512 134220221252736 train_trans.py:273] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-1\n",
            "INFO:tensorflow:Starting training ... \n",
            "I0213 04:13:57.008163 134220221252736 train_trans.py:331] Starting training ... \n",
            "‚úÖ GNN Graph Construction: 175 nodes (from Input Length 175)\n",
            "I0000 00:00:1770956042.044994    7808 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "INFO:tensorflow:[   500] | gnorm  1.11 lr  0.000244 | loss  5.58\n",
            "I0213 04:14:09.828490 134220221252736 train_trans.py:345] [   500] | gnorm  1.11 lr  0.000244 | loss  5.58\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.55\n",
            "I0213 04:14:11.453685 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.55\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.56\n",
            "I0213 04:14:12.202406 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.56\n",
            "I0213 04:14:12.277471 134220221252736 functional_saver.py:440] Sharding callback duration: 39 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-2\n",
            "I0213 04:14:12.290918 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-2\n",
            "INFO:tensorflow:[  1000] | gnorm  0.88 lr  0.000226 | loss  5.57\n",
            "I0213 04:14:17.011113 134220221252736 train_trans.py:345] [  1000] | gnorm  0.88 lr  0.000226 | loss  5.57\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.55\n",
            "I0213 04:14:18.217362 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.55\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.56\n",
            "I0213 04:14:18.620454 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.56\n",
            "I0213 04:14:18.672530 134220221252736 functional_saver.py:440] Sharding callback duration: 34 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-3\n",
            "I0213 04:14:18.679941 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-3\n",
            "INFO:tensorflow:[  1500] | gnorm  0.80 lr  0.000199 | loss  5.56\n",
            "I0213 04:14:23.399926 134220221252736 train_trans.py:345] [  1500] | gnorm  0.80 lr  0.000199 | loss  5.56\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.55\n",
            "I0213 04:14:24.603797 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.55\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:25.004460 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:25.053296 134220221252736 functional_saver.py:440] Sharding callback duration: 29 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-4\n",
            "I0213 04:14:25.059904 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-4\n",
            "INFO:tensorflow:[  2000] | gnorm  0.75 lr  0.000164 | loss  5.56\n",
            "I0213 04:14:29.785434 134220221252736 train_trans.py:345] [  2000] | gnorm  0.75 lr  0.000164 | loss  5.56\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.55\n",
            "I0213 04:14:30.998353 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.55\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:31.406343 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:31.455373 134220221252736 functional_saver.py:440] Sharding callback duration: 34 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-5\n",
            "I0213 04:14:31.462094 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-5\n",
            "INFO:tensorflow:[  2500] | gnorm  0.72 lr  0.000125 | loss  5.56\n",
            "I0213 04:14:36.183623 134220221252736 train_trans.py:345] [  2500] | gnorm  0.72 lr  0.000125 | loss  5.56\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.54\n",
            "I0213 04:14:37.386671 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.54\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:37.786761 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:37.834638 134220221252736 functional_saver.py:440] Sharding callback duration: 26 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-6\n",
            "I0213 04:14:37.841038 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-6\n",
            "INFO:tensorflow:[  3000] | gnorm  0.69 lr  0.000087 | loss  5.56\n",
            "I0213 04:14:42.563159 134220221252736 train_trans.py:345] [  3000] | gnorm  0.69 lr  0.000087 | loss  5.56\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.54\n",
            "I0213 04:14:43.766936 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.54\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:44.180851 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:44.230844 134220221252736 functional_saver.py:440] Sharding callback duration: 34 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-7\n",
            "I0213 04:14:44.237431 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-7\n",
            "INFO:tensorflow:[  3500] | gnorm  0.68 lr  0.000052 | loss  5.55\n",
            "I0213 04:14:48.955648 134220221252736 train_trans.py:345] [  3500] | gnorm  0.68 lr  0.000052 | loss  5.55\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.54\n",
            "I0213 04:14:50.156644 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.54\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:50.571492 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:50.619500 134220221252736 functional_saver.py:440] Sharding callback duration: 26 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-8\n",
            "I0213 04:14:50.625860 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-8\n",
            "INFO:tensorflow:[  4000] | gnorm  0.67 lr  0.000025 | loss  5.55\n",
            "I0213 04:14:55.346348 134220221252736 train_trans.py:345] [  4000] | gnorm  0.67 lr  0.000025 | loss  5.55\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.54\n",
            "I0213 04:14:56.555621 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.54\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:56.955185 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:14:57.003597 134220221252736 functional_saver.py:440] Sharding callback duration: 31 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-9\n",
            "I0213 04:14:57.010328 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-9\n",
            "INFO:tensorflow:[  4500] | gnorm  0.67 lr  0.000007 | loss  5.55\n",
            "I0213 04:15:01.731716 134220221252736 train_trans.py:345] [  4500] | gnorm  0.67 lr  0.000007 | loss  5.55\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.54\n",
            "I0213 04:15:02.942170 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.54\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:15:03.352544 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:15:03.401053 134220221252736 functional_saver.py:440] Sharding callback duration: 31 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-10\n",
            "I0213 04:15:03.407896 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-10\n",
            "INFO:tensorflow:[  5000] | gnorm  0.67 lr  0.000001 | loss  5.55\n",
            "I0213 04:15:08.126195 134220221252736 train_trans.py:345] [  5000] | gnorm  0.67 lr  0.000001 | loss  5.55\n",
            "INFO:tensorflow:Train batches[  312]                | loss  5.54\n",
            "I0213 04:15:09.343588 134220221252736 train_trans.py:361] Train batches[  312]                | loss  5.54\n",
            "INFO:tensorflow:Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:15:09.749766 134220221252736 train_trans.py:371] Eval  batches[  312]                | loss  5.55\n",
            "I0213 04:15:09.802918 134220221252736 functional_saver.py:440] Sharding callback duration: 29 microseconds\n",
            "INFO:tensorflow:Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-11\n",
            "I0213 04:15:09.809399 134220221252736 train_trans.py:381] Model saved in path: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-11\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# TRAIN GNN MODEL IN COLAB\n",
        "# ============================================================================\n",
        "# Paste this into a new Colab cell\n",
        "\n",
        "print(\"üî∑ Training GNN Model\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    'checkpoint_dir': '/content/drive/MyDrive/EstraNet/checkpoints_gnn',\n",
        "    'result_path': 'results/gnn',\n",
        "    'train_steps': 5000,\n",
        "    'save_steps': 200,\n",
        "    'train_batch_size': 256,\n",
        "    'eval_batch_size': 32,\n",
        "    'learning_rate': 0.00025,\n",
        "    'model_type': 'gnn',  # KEY: Use GNN\n",
        "}\n",
        "\n",
        "import os\n",
        "os.makedirs(CONFIG['checkpoint_dir'], exist_ok=True)\n",
        "os.makedirs(CONFIG['result_path'], exist_ok=True)\n",
        "\n",
        "# Build training command\n",
        "train_cmd = f\"\"\"\n",
        "python train_trans.py \\\\\n",
        "    --data_path=data/ASCAD.h5 \\\\\n",
        "    --checkpoint_dir={CONFIG['checkpoint_dir']} \\\\\n",
        "    --model_type={CONFIG['model_type']} \\\\\n",
        "    --dataset=ASCAD \\\\\n",
        "    --input_length=700 \\\\\n",
        "    --eval_batch_size={CONFIG['eval_batch_size']} \\\\\n",
        "    --n_layer=2 \\\\\n",
        "    --d_model=128 \\\\\n",
        "    --d_inner=256 \\\\\n",
        "    --n_head_softmax=8 \\\\\n",
        "    --d_head_softmax=16 \\\\\n",
        "    --dropout=0.05 \\\\\n",
        "    --conv_kernel_size=3 \\\\\n",
        "    --n_conv_layer=2 \\\\\n",
        "    --pool_size=2 \\\\\n",
        "    --beta_hat_2=150 \\\\\n",
        "    --model_normalization=preLC \\\\\n",
        "    --softmax_attn=True \\\\\n",
        "    --do_train=True \\\\\n",
        "    --learning_rate={CONFIG['learning_rate']} \\\\\n",
        "    --clip=0.25 \\\\\n",
        "    --min_lr_ratio=0.004 \\\\\n",
        "    --warmup_steps=0 \\\\\n",
        "    --train_batch_size={CONFIG['train_batch_size']} \\\\\n",
        "    --train_steps={CONFIG['train_steps']} \\\\\n",
        "    --iterations=500 \\\\\n",
        "    --save_steps={CONFIG['save_steps']} \\\\\n",
        "    --result_path={CONFIG['result_path']}\n",
        "\"\"\"\n",
        "\n",
        "print(\"Starting GNN training...\")\n",
        "print(f\"Model: GNN (211,876 parameters - 51% less than Transformer)\")\n",
        "print(f\"Checkpoints: {CONFIG['checkpoint_dir']}\")\n",
        "print(f\"Training steps: {CONFIG['train_steps']:,}\\n\")\n",
        "\n",
        "!{train_cmd}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TEST GNN ARCHITECTURE (Rank 29 Config)\n",
        "# ============================================================================\n",
        "# Paste into a Colab cell to verify the model builds correctly\n",
        "# with the 'Rank 29' parameters (Pool=2, Input=700).\n",
        "\n",
        "!python test_gnn.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRg5hbdROo8Q",
        "outputId": "c9559bc4-2d91-48d9-abb1-ed5de507dc61"
      },
      "id": "oRg5hbdROo8Q",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-13 04:25:06.751573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770956706.772463   11915 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770956706.779156   11915 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770956706.795279   11915 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770956706.795306   11915 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770956706.795309   11915 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770956706.795312   11915 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "======================================================================\n",
            "Testing GNN-based EstraNet\n",
            "======================================================================\n",
            "\n",
            "üèóÔ∏è  Building GNN model...\n",
            "Configuration:\n",
            "  n_gcn_layers: 2\n",
            "  d_model: 128\n",
            "  k_neighbors: 5\n",
            "  graph_pooling: mean\n",
            "  d_head_softmax: 16\n",
            "  n_head_softmax: 8\n",
            "  dropout: 0.05\n",
            "  n_classes: 256\n",
            "  conv_kernel_size: 3\n",
            "  n_conv_layer: 2\n",
            "  pool_size: 2\n",
            "  beta_hat_2: 150\n",
            "  model_normalization: preLC\n",
            "  softmax_attn: True\n",
            "  output_attn: False\n",
            "2026-02-13 04:25:13.033343: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770956713.034323   11915 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 77658 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:05.0, compute capability: 8.0\n",
            "\n",
            "üî® Building model graph with dummy input...\n",
            "‚úÖ GNN Graph Construction: 175 nodes (from Input Length 175)\n",
            "I0000 00:00:1770956713.998070   11915 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "‚úÖ Model built successfully!\n",
            "   Input shape:  (1, 700)\n",
            "   Output shape: (1, 256)\n",
            "\n",
            "üìä Model Parameters: 180,001\n",
            "\n",
            "üìà Comparison:\n",
            "   Transformer: 431,233 parameters\n",
            "   Mamba:       425,569 parameters\n",
            "   GNN:         180,001 parameters\n",
            "   üéØ GNN has 58.3% fewer parameters than Transformer!\n",
            "\n",
            "üß™ Testing forward pass with random data...\n",
            "   Batch input shape:  (4, 700)\n",
            "   Batch output shape: (4, 256)\n",
            "   ‚úÖ Forward pass successful!\n",
            "\n",
            "======================================================================\n",
            "‚úÖ GNN Model Test Complete!\n",
            "======================================================================\n",
            "\n",
            "You can now use --model_type=gnn in train_trans.py\n",
            "\n",
            "Example:\n",
            "  python train_trans.py \\\n",
            "    --model_type=gnn \\\n",
            "    --data_path=data/ASCAD.h5 \\\n",
            "    --train_steps=50000 \\\n",
            "    --checkpoint_dir=./checkpoints_gnn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cb82f2c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb82f2c9",
        "outputId": "6648d70a-8e57-44e5-f9c5-1e8652f702e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Evaluating GNN Checkpoints (Correct Config)\n",
            "======================================================================\n",
            "\n",
            "üì• Loading ASCAD dataset...\n",
            "‚úÖ Loaded 2000 traces (Length: 700)\n",
            "   Trace Type: float32 (Must be float32)\n",
            "\n",
            "üèóÔ∏è Building GNN model...\n",
            "‚úÖ GNN Graph Construction: 175 nodes (from Input Length 175)\n",
            "‚úÖ Model Built (Pool Size: 2)\n",
            "üìÇ Searching for checkpoints in: /content/drive/MyDrive/EstraNet/checkpoints_gnn\n",
            "‚úÖ Found 11 checkpoints.\n",
            "\n",
            "Testing gnn_ASCAD-1...\n",
            "üèÜ Rank: 1.00 | Broken at: 1473 traces\n",
            "\n",
            "Testing gnn_ASCAD-10...\n",
            "üèÜ Rank: 203.00 | Broken at: >2000 traces\n",
            "\n",
            "Testing gnn_ASCAD-11...\n",
            "üèÜ Rank: 204.00 | Broken at: >2000 traces\n",
            "\n",
            "Testing gnn_ASCAD-2...\n",
            "üèÜ Rank: 210.00 | Broken at: >2000 traces\n",
            "\n",
            "Testing gnn_ASCAD-3...\n",
            "üèÜ Rank: 206.00 | Broken at: >2000 traces\n",
            "\n",
            "Testing gnn_ASCAD-4...\n",
            "üèÜ Rank: 204.00 | Broken at: >2000 traces\n",
            "\n",
            "Testing gnn_ASCAD-5...\n",
            "üèÜ Rank: 205.00 | Broken at: >2000 traces\n",
            "\n",
            "Testing gnn_ASCAD-6...\n",
            "üèÜ Rank: 205.00 | Broken at: >2000 traces\n",
            "\n",
            "Testing gnn_ASCAD-7...\n",
            "üèÜ Rank: 205.00 | Broken at: >2000 traces\n",
            "\n",
            "Testing gnn_ASCAD-8...\n",
            "üèÜ Rank: 207.00 | Broken at: >2000 traces\n",
            "\n",
            "Testing gnn_ASCAD-9...\n",
            "üèÜ Rank: 207.00 | Broken at: >2000 traces\n",
            "\n",
            "‚úÖ Evaluation Complete.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# EVALUATE GNN (RANK 29 MODEL)\n",
        "# ============================================================================\n",
        "# This script evaluates the CORRECT configuration (Pool=2, Input=700).\n",
        "\n",
        "print(\"üîç Evaluating GNN Checkpoints (Correct Config)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "import glob\n",
        "from gnn_estranet import GNNEstraNet\n",
        "from evaluation_utils import compute_key_rank\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# CONFIGURATION\n",
        "# ----------------------------------------------------------------------------\n",
        "# Must match RETRAIN_GNN_CORRECTED.txt\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/EstraNet/checkpoints_gnn'\n",
        "INPUT_LENGTH = 700\n",
        "POOL_SIZE = 2\n",
        "N_TRACES = 2000 # Fast check (use 10000 for full precision)\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# 1. LOAD DATA\n",
        "# ----------------------------------------------------------------------------\n",
        "print(\"\\nüì• Loading ASCAD dataset...\")\n",
        "with h5py.File('data/ASCAD.h5', 'r') as f:\n",
        "    # Load limited traces for speed\n",
        "    traces = f['Attack_traces']['traces'][:N_TRACES]\n",
        "    metadata = f['Attack_traces']['metadata'][:N_TRACES]\n",
        "\n",
        "    # Process inputs (Slice to 700)\n",
        "    traces = traces[:, :INPUT_LENGTH]\n",
        "\n",
        "    # FIX: Cast to float32 for TensorFlow model\n",
        "    # This prevents the \"Value passed to parameter 'input' has DataType int8\" error\n",
        "    traces = traces.astype(np.float32)\n",
        "\n",
        "    # Extract labels/keys\n",
        "    plaintexts = metadata['plaintext'][:, 2].astype(np.uint8)\n",
        "    keys = metadata['key'][:, 2].astype(np.uint8)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(traces)} traces (Length: {traces.shape[1]})\")\n",
        "print(f\"   Trace Type: {traces.dtype} (Must be float32)\")\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# 2. BUILD MODEL (Correct Rank 29 Config)\n",
        "# ----------------------------------------------------------------------------\n",
        "print(\"\\nüèóÔ∏è Building GNN model...\")\n",
        "model = GNNEstraNet(\n",
        "    n_gcn_layers=2,\n",
        "    d_model=128,\n",
        "    k_neighbors=5,\n",
        "    graph_pooling='mean',\n",
        "    d_head_softmax=16,\n",
        "    n_head_softmax=8,\n",
        "    dropout=0.05,\n",
        "    n_classes=256,\n",
        "    conv_kernel_size=3,\n",
        "    n_conv_layer=2,\n",
        "    pool_size=POOL_SIZE,  # CRITICAL: Must be 2\n",
        "    beta_hat_2=150,\n",
        "    model_normalization='preLC',\n",
        "    softmax_attn=True,\n",
        "    output_attn=False\n",
        ")\n",
        "\n",
        "# Dummy pass to initialize weights\n",
        "# Using float32 input explicitly\n",
        "dummy_input = tf.zeros((1, INPUT_LENGTH), dtype=tf.float32)\n",
        "model(dummy_input, softmax_attn_smoothing=None, training=False)\n",
        "print(f\"‚úÖ Model Built (Pool Size: {POOL_SIZE})\")\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# 3. EVALUATE CHECKPOINTS\n",
        "# ----------------------------------------------------------------------------\n",
        "if not os.path.exists(CHECKPOINT_DIR):\n",
        "    print(f\"‚ùå Error: Checkpoint folder not found: {CHECKPOINT_DIR}\")\n",
        "    # Fallback to local\n",
        "    CHECKPOINT_DIR = 'checkpoints'\n",
        "\n",
        "print(f\"üìÇ Searching for checkpoints in: {CHECKPOINT_DIR}\")\n",
        "ckpt_files = sorted(glob.glob(os.path.join(CHECKPOINT_DIR, \"*.index\")))\n",
        "if not ckpt_files:\n",
        "    print(\"‚ùå No checkpoints found!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Found {len(ckpt_files)} checkpoints.\")\n",
        "\n",
        "for ckpt_path in ckpt_files:\n",
        "    # Remove extension to get prefix\n",
        "    prefix = ckpt_path.replace(\".index\", \"\")\n",
        "    fname = os.path.basename(prefix)\n",
        "\n",
        "    print(f\"\\nTesting {fname}...\")\n",
        "    try:\n",
        "        ckpt = tf.train.Checkpoint(model=model)\n",
        "        ckpt.restore(prefix).expect_partial()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Failed to load {fname}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Inference\n",
        "    try:\n",
        "        preds = model.predict(traces, batch_size=256, verbose=0)\n",
        "\n",
        "        # FIX: Handle tuple return (e.g. if model returns (logits, attn))\n",
        "        if isinstance(preds, tuple):\n",
        "            preds = preds[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Prediction failed for {fname}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Rank\n",
        "    # Compute rank evolution (returns array of ranks for 1..N traces)\n",
        "    try:\n",
        "        ranks = compute_key_rank(preds, plaintexts, keys)\n",
        "        final_rank = ranks[-1]\n",
        "\n",
        "        # Check efficiency (traces to rank 0)\n",
        "        success_idx = np.where(ranks == 0)[0]\n",
        "        traces_to_0 = success_idx[0] + 1 if len(success_idx) > 0 else \">\" + str(N_TRACES)\n",
        "\n",
        "        print(f\"üèÜ Rank: {final_rank:.2f} | Broken at: {traces_to_0} traces\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Rank computation failed: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Evaluation Complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faf6db47",
        "outputId": "18873429-a57f-4f45-9daa-07eab46e4a2c"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Locations to check\n",
        "locations = [\n",
        "    '/content/drive/MyDrive/EstraNet/checkpoints_gnn',\n",
        "    '/content/EstraNet/checkpoints',\n",
        "    'checkpoints',\n",
        "]\n",
        "\n",
        "print(\"üîç Checking for checkpoints...\")\n",
        "found_any = False\n",
        "for loc in locations:\n",
        "    if os.path.exists(loc):\n",
        "        files = glob.glob(os.path.join(loc, \"*.index\"))\n",
        "        if files:\n",
        "            print(f\"‚úÖ Found {len(files)} checkpoints in: {loc}\")\n",
        "            print(f\"   Example: {files[0]}\")\n",
        "            found_any = True\n",
        "            # Update the variable for the next cell\n",
        "            actual_checkpoint_dir = loc\n",
        "        else:\n",
        "            print(f\"‚ùå Folder exists but empty: {loc}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Folder not found: {loc}\")\n",
        "\n",
        "if not found_any:\n",
        "    print(\"\\n‚ö†Ô∏è No checkpoints found in expected locations.\")"
      ],
      "id": "faf6db47",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Checking for checkpoints...\n",
            "‚úÖ Found 11 checkpoints in: /content/drive/MyDrive/EstraNet/checkpoints_gnn\n",
            "   Example: /content/drive/MyDrive/EstraNet/checkpoints_gnn/gnn_ASCAD-7.index\n",
            "‚úÖ Found 1 checkpoints in: /content/EstraNet/checkpoints\n",
            "   Example: /content/EstraNet/checkpoints/trans_long-8.index\n",
            "‚úÖ Found 1 checkpoints in: checkpoints\n",
            "   Example: checkpoints/trans_long-8.index\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}